{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80f2b2c-3e4c-4ce3-a977-c822989b3e67",
   "metadata": {},
   "source": [
    "# **Machine Learning Reconstruction of Surface Ocean pCO₂**\n",
    "Spring 2025, EESC4243/STAT4243/5243 “Climate Prediction Challenges with Machine Learning”, Columbia University\n",
    "\n",
    "## Introduction \n",
    "The ocean plays a crucial role in the global carbon cycle by absorbing atmospheric CO₂, having absorbed 38% of all anthropogenic fossil fuel emissions over the industrial era. \n",
    "\n",
    "Accurate estimation of air–sea CO₂ flux is critical for understanding the current and future global carbon budget, yet remains challenging due to the sparse and unevenly distributed nature of surface ocean pCO₂ observations. The **Surface Ocean CO₂ Atlas (SOCAT)** database (https://socat.info/) provides the most extensive dataset available, but its coverage is limited to only about 2% of all boxes of 1 degree X 1 degree (= 100km X 100km at the equator) over the last several decades. Data are particularly limited in high-latitude regions and during winter months.\n",
    "\n",
    "To fill in the gaps in these data, statistical and machine learning (ML) techniques have been widely used to reconstruct global pCO₂ fields by interpolating between observations using environmental predictors such as sea surface temperature (SST), sea surface salinity (SSS), mixed layer depth (MLD), chlorophyll-a (Chl-a), and atmospheric CO₂ (xCO₂).\n",
    "\n",
    "How good are these methods? Since the real full-coverage pCO2 of the ocean is unknown, we need another approach to assess the skill of ML-based reconstructions. Our answer is the **Large Ensemble Testbed (LET)**, which provides full-coverage pCO₂ output from Earth System Models, as well as associated driver varibles also from the ESM. In the context of this testbed, we can sample the pCO2 in the same pattern as real-world SOCAT and then reconstruct. Since the full-field pCO2 field is known (\"Model Truth\"), we can directly evaluate of ML reconstruction performance. With this approach, it has been shown that ML methods can capture seasonal variability well, they often overestimate decadal variability, particularly in regions with limited data coverage (Gloege et al. 2021).\n",
    "\n",
    "This study builds upon previous work by incorporating a **pCO₂-Residual** approach to improve ML-based pCO₂ reconstructions. The **pCO₂-Residual** method removes the temperature-driven component from pCO₂ before applying ML, thereby reducing the dominance of temperature in predictions and enhancing the ability of the model to capture non-temperature-driven variability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5841700-a1f2-4ca9-9708-6e01b5539535",
   "metadata": {},
   "source": [
    "\n",
    "We reproduce a portion of the analysis carried out by  \n",
    "**Gloege et al. (2021)** *\"Quantifying Errors in Observationally Based Estimates of Ocean Carbon Sink Variability.\"* **Global Biogeochemical Cycles** 34: e2020GB006788.  \n",
    "([DOI: 10.1029/2020GB006788](https://doi.org/10.1029/2020GB006788))  \n",
    "\n",
    "using the method of  \n",
    "**Bennington et al. (2022)** *\"Explicit Physical Knowledge in Machine Learning for Ocean Carbon Flux Reconstruction: The pCO2-Residual Method\"*. **Journal of Advances in Modeling Earth Systems**, 14(10). ([DOI: 10.1029/2021ms002960](https://doi.org/10.1029/2021ms002960))\n",
    "\n",
    "Our study:\n",
    "1. Implements an **XGBoost-based pCO₂-Residual reconstruction**  (Bennington et al. 2022).\n",
    "2. Implements a **Feed Forward Neural Network**\n",
    "3. Evaluates reconstruction performance using a Large Ensemble Testbed, with **bias and correlation metrics** as in Gloege et al (2021).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163e5b0-d999-4dfb-ab8c-40f8e3318b5e",
   "metadata": {},
   "source": [
    "### Running Notes\n",
    "1. Users need to enter their GitHub/LEAP-Pangeo username at the end of Section 2.\n",
    "2. Several time-consuming steps have outputs saved to files, so they only need to be run initially or if changes are made:  \n",
    "    - Section 4.3: ML Training (~1 minute/ESM member)  \n",
    "    - Section 4.4: Reconstruction/Inference (~1 minute/ESM member)  \n",
    "    - Section 4.4.1: Summation of pCO2-Residual and pCO2-T to recover pCO2 (~15 seconds/ESM member)\n",
    "\n",
    "\n",
    "    With a **128GB CPU**, actual runtimes may vary based on system load and selected members, but this serves as a general guideline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51674379-0ce7-41b3-b6ce-f654fc6f89a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>your_username:</b> The username of the person running the code. \n",
    "<p><b>owner_username:</b> The username of the notebook owner.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892580c-f016-4fc2-94f9-60912cebcc6e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>runthiscell:</b>(Default = 1) Disable a cell by setting <b>runthiscell=0</b>. Reviewers should set <b>runthiscell=-1</b> to save time and space. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1bb72f-9997-4e54-a0d6-f0e28f87d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_username = 'JuanPalaciosGodoy'  # username of the person running the code. Reviewers should also change this to their own username.\n",
    "\n",
    "#To allow the reviewer to access the saved files, provide notebook owner's username here:  \n",
    "owner_username = 'JuanPalaciosGodoy'  # Reviewer should not change this name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c6783-624f-486a-bafe-672ec7a9d73c",
   "metadata": {},
   "source": [
    "## **2.1 Input (Features) Sources**\n",
    "The **input features** for the machine learning model are derived from **pre-processed Earth System Model (ESM) outputs or inputs**\n",
    "\n",
    "### **Feature and Target Variables for the ML Model**\n",
    "The features used for training the **pCO₂-Residual machine learning model** are listed below:\n",
    "\n",
    "\n",
    "| **Feature** | **Description** | **ESM Input or Output?** | \n",
    "|------------|----------------|----------------|\n",
    "| **SST (Sea Surface Temperature)** | Simulated ocean surface temperature | **ESM Output** |  \n",
    "| **SST_anom** | SST anomaly from climatology | **ESM Output** |  \n",
    "| **SSS (Sea Surface Salinity)** | Simulated surface ocean salinity | **ESM Output** |  \n",
    "| **SSS_anom** | SSS anomaly from climatology | **ESM Output** |  \n",
    "| **MLD_clim_log** | Log-transformed climatological mixed layer depth | **ESM Output** |  \n",
    "| **Chl-a (Chlorophyll concentration)** | Proxy for biological activity (log-transformed) | **ESM Output** |  \n",
    "| **Chl-a_anom** | Anomaly of Chl-a | **ESM Output** |  \n",
    "| **xCO₂ (Atmospheric CO₂ concentration)** | Atmospheric CO₂ mole fraction | **ESM Input, from data** |  \n",
    "| **A, B, C** | Space on the globe | **See Bennington et al. 2022, Table 1** |  \n",
    "| **T0, T1** | Time | **See Bennington et al. 2022, Table 1** |  \n",
    "\n",
    "\n",
    "The **target variable** for reconstruction is:\n",
    "- **pCO₂-Residual**: This deviation from the temperature-driven component of pCO₂, reducing SST's dominance in ML reconstructions and improving model performance in data-sparse regions (detailed below).\n",
    "- **pCO₂-Residual-trend**: This is the trend component of pCO₂-Residual\n",
    "- **pCO₂-Residual-seasonal**: This is the seasonal component of pCO₂-Residual\n",
    "- **pCO₂-Residual-deseasonal**: This is the de-seasonal component of pCO₂-Residual\n",
    "\n",
    "### **Key Considerations:**\n",
    "- **pCO₂-Residual**: By removing the temperature-driven component from pCO₂, we enhance the ability of machine learning models to capture **non-temperature-driven variability**, particularly in poorly observed regions.\n",
    "- **pCO₂-Residual** = pCO₂-Residual-trend + pCO₂-Residual-seasonal + pCO₂-Residual-deseasonal\n",
    "- **Data Subsampling Based on SOCAT**: The use of a **SOCAT-derived mask** ensures that the ML model is trained and evaluated using a realistic observational distribution, mitigating potential biases from uneven data coverage.\n",
    "\n",
    "### **Final Input Structure**:\n",
    "- **Feature Matrix**: `(N, 12)`, where `N` represents the number of samples, and 12 predictor variables are used.\n",
    "- **Target Variable**: `pCO₂-Residual`, which the model aims to reconstruct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41349631-8b5a-4750-ac9e-e65431db3600",
   "metadata": {},
   "source": [
    "# 0.1. Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4259b69-596f-403b-80ef-a4db5dad096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for ML:\n",
    "features_sel = ['sst','sst_anom','sss','sss_anom','mld_clim_log','chl_log','chl_log_anom','xco2','A', 'B', 'C', 'T0', 'T1']\n",
    "\n",
    "# the target variable we reconstruct:\n",
    "target_sel = ['pco2_residual_deseasonal'] #pco2_residual: this represents pCO2 - pCO2-T (calculated in notebook 00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78934e6-b3db-4412-a8fc-9f85b6daee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range\n",
    "__MODEL_TYPE__ = \"nn\" # \"xgb\" or \"nn\"\n",
    "__GRID_SEARCH_APPROACH__ = 'nmse'\n",
    "__DATE_RANGE_START__ = '2004-01-01T00:00:00.000000000'\n",
    "__DATE_RANGE_END__ = '2023-12-31T00:00:00.000000000'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80186cf7-27c4-4f0c-8c56-44c90c649b76",
   "metadata": {},
   "source": [
    "# 0. Setup Workspace and Import Packages\n",
    "We use %%capture to suppress output and keep the notebook clean. However, feel free to remove it if you want to check warnings or logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37add44-d2ae-4e76-bc1a-effea1531dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42d82f8-8400-459b-890c-f8ebfc9799e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745368787.056195    1667 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745368787.063282    1667 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745368787.083868    1667 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745368787.083899    1667 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745368787.083901    1667 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745368787.083904    1667 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "### standard imports ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import gcsfs\n",
    "import fsspec\n",
    "import torch\n",
    "### Python file with supporting functions ###\n",
    "# standard imports\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import sys\n",
    "# Redirect all low-level stderr output\n",
    "sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "import csv\n",
    "import cmocean as cm\n",
    "\n",
    "# machine learning libraries\n",
    "import xgboost as xgb     \n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Change to the parent directory of the current working directory. (Run only once—otherwise it will keep moving up the directory tree)\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Python file with supporting functions\n",
    "import lib.residual_utils as supporting_functions\n",
    "from lib.visualization import *\n",
    "from lib.bias_figure2 import concat_datasets, XarrayEvaluator\n",
    "from lib.corr_figure3 import eval_spatial\n",
    "from lib.paths_utils import SavingPaths\n",
    "from lib.model_utils import train_member_models, Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df9df76f-dfcb-4044-9a7e-c096f121e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the date range to unify the date type ###\n",
    "\n",
    "# create date vector, adds 14 days to start & end\n",
    "dates = pd.date_range(start=__DATE_RANGE_START__, \n",
    "                      end=__DATE_RANGE_END__,freq='MS')\n",
    "\n",
    "\n",
    "init_date = str(dates[0].year) + format(dates[0].month,'02d')\n",
    "fin_date = str(dates[-1].year) + format(dates[-1].month,'02d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb0d50-93db-49cf-9f2c-451d007df70e",
   "metadata": {},
   "source": [
    "\n",
    "### **Output Data Storage and Model Saving**\n",
    "\n",
    "The output data generated by this notebook, including model predictions, performance metrics, and trained models, is saved in a cloud-based environment using a user-specific directory structure. This ensures that each user’s results are organized and accessible without interfering with others’ work.\n",
    "\n",
    "The output data is organized into three main categories:  \n",
    "1. **Machine Learning Models:** Trained models are saved for future use, ensuring that results can be replicated without re-training.  \n",
    "2. **Reconstructions:** Predicted pCO₂ fields are stored for further analysis and visualization.  \n",
    "3. **Performance Metrics:** CSV files containing test and unseen data performance metrics are saved for easy evaluation.\n",
    "\n",
    "### **Data Sources and Paths**\n",
    "The data is stored in a **cloud environment, LEAP-Pangeo**, ensuring efficient access and scalability for the machine learning workflow. Key datasets include:\n",
    "\n",
    "- **Ensemble dir**:\n",
    "\n",
    "  Contains the original data from pre-processed Earth System Model (ESM) outputs, available for 100+ ESM members. For computational efficiency, we rely on a selection of this dataset compiled by TA Xinyi Ke. The full ensemble data is available and could be explored, with due consideration of storage constraints. \n",
    "  \n",
    "- **ML Input and Target Data**:\n",
    "\n",
    "    Provides a dataframe-format dataset containing preprocessed ML inputs and ground truth from a selected subset of ensemble members. You may also generate your own dataset for a custom selection or range of members (see reference: Project3_Data.ipynb). Due to limited GCS storage, we recommend using the provided dataset for most projects.\n",
    "  \n",
    "- **SOCAT Data (Mask File)**:  \n",
    "\n",
    "  Masking file based on real-world **SOCAT pCO₂ observations**. Here, these data are not used directly, but are input solely so that their sampling pattern in space and time can be applied to model pCO2 fields, thus mimicing real-world observational density.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8fe335d-44e6-4d74-9697-50fc5e5780c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loading and saving paths\n",
    "saving_paths = SavingPaths(\n",
    "    your_username=your_username,\n",
    "    owner_username=owner_username,\n",
    "    init_date=init_date,\n",
    "    fin_date=fin_date,\n",
    "    grid_search_approach=__GRID_SEARCH_APPROACH__,\n",
    "    model=__MODEL_TYPE__\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb335b-cbbb-4c58-9482-466ee7735f2a",
   "metadata": {},
   "source": [
    "# 1. Surface ocean pCO2: A sparse data challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d0931f-c23f-4794-9862-c001ba1d32b5",
   "metadata": {},
   "source": [
    "SOCAT data coverage is uneven, with some regions, particularly in the Southern Hemisphere and open ocean areas, having significantly fewer observations. Regions with denser observational coverage, such as the Northern Hemisphere, tend to have lower biases in CO2 flux reconstructions compared to sparsely sampled areas like the Southern Ocean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f69c8-22f6-4d6c-9ab6-5748f9d4df36",
   "metadata": {},
   "source": [
    "# 2. Data Introduction and Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febda34-4029-426c-aa0d-34445a3635f8",
   "metadata": {},
   "source": [
    " **Compute the temperature-driven component** of pCO₂:\n",
    "\n",
    "$$\n",
    "\\text{pCO}_{2,T} = \\overline{\\text{pCO}_2} \\cdot \\exp\\left[ 0.0423 \\cdot (T - \\overline{T}) \\right]\n",
    "$$\n",
    "\n",
    "- $ \\overline{\\text{pCO}_2} $: long-term mean of surface ocean pCO₂  \n",
    "- $ T $: sea surface temperature at a given time/location  \n",
    "- $ \\overline{T} $: long-term mean sea surface temperature  \n",
    "- $ 0.0423 $: empirically derived constant (from Takahashi et al., 1993)\n",
    "\n",
    "\n",
    " **Subtract to get the residual**:\n",
    "\n",
    "$$\n",
    "\\text{pCO}_{2,\\text{Residual}} = \\text{pCO}_2 - \\text{pCO}_{2,T}\n",
    "$$\n",
    "\n",
    "The residual is then decomposed into three separate components such that:\n",
    "\n",
    "$$\n",
    "\\text{pCO}_{2,\\text{Residual}} = \\text{pCO}_{2,seasonal} + \\text{pCO}_{2,deseasonal} + \\text{pCO}_{2,trend}\n",
    "$$\n",
    "\n",
    "The seasonal and deseasonal components are then used as the **target variables** in ML training, helping disentangle the direct solubility-driven temperature effect from other biogeochemical processes.\n",
    "\n",
    "In our workflow, this calculation was done during processing of the Earth System Model (ESM) dataset, not included in this notebook. The datasets under `ensemble_dir` include the variable `pCO2_T`. For this notebook, we will directly use the preprocessed ML input dataset, which includes `pco2_residual`.\n",
    "\n",
    "Later in the notebook, we recover the total pCO2 by **adding the temperature component back** to the residual:\n",
    "\n",
    "$$\n",
    "\\text{pCO}_2 = \\text{pCO}_{2,\\text{Residual}} + \\text{pCO}_{2,T}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2a655f4-fa0a-4a42-ab1c-acbbb3d1de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up for getting files from leap bucket ###\n",
    "fs = gcsfs.GCSFileSystem()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1022e3-160e-49e7-8620-83add5264a18",
   "metadata": {},
   "source": [
    "# 3.  Earth System Models and their Ensemble Members\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec31f06e-b223-46a8-8964-2b55d03f0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "mems_dict = dict()\n",
    "\n",
    "# Get all paths\n",
    "all_paths = fs.ls(saving_paths.inputs_path)\n",
    "\n",
    "for ens_path in all_paths:             \n",
    "    ens = ens_path.split('/')[-1]\n",
    "    mems = fs.ls(ens_path)\n",
    "    for mem in mems:        \n",
    "        memo = mem.split('/')[-1]\n",
    "        if ens not in mems_dict:\n",
    "            mems_dict[ens] = [memo]\n",
    "        elif ens in mems_dict:\n",
    "            mems_dict[ens].append(memo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5e36a5e-a4b9-4bce-83df-8b825d653d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACCESS-ESM1-5': ['member_r10i1p1f1', 'member_r5i1p1f1', 'member_r2i1p1f1'], 'CanESM5': ['member_r2i1p1f1', 'member_r1i1p2f1', 'member_r1i1p1f1'], 'MPI-ESM1-2-LR': ['member_r12i1p1f1', 'member_r11i1p1f1', 'member_r15i1p1f1']}\n"
     ]
    }
   ],
   "source": [
    "## Here you can change which models and how many members you use\n",
    "random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "selected_ensembles = ['ACCESS-ESM1-5', 'CanESM5', 'MPI-ESM1-2-LR']\n",
    "\n",
    "selected_members_dict = {esm: mems_dict[esm] for esm in selected_ensembles}\n",
    "\n",
    "selected_mems_dict = {}\n",
    "num_members = 3  # Set the number of ensemble members from each ESM\n",
    "\n",
    "for ens, members in selected_members_dict.items():\n",
    "    if len(members) >= num_members:\n",
    "        selected_mems_dict[ens] = random.sample(members, num_members)  # Select `num_members` random members\n",
    "    else:\n",
    "        selected_mems_dict[ens] = members  # If there are fewer members than `num_members`, select all\n",
    "\n",
    "print(selected_mems_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e1073-7eca-425e-877b-3d6e0e017fba",
   "metadata": {},
   "source": [
    "# 4. ML Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df916e52-50fa-44ff-a767-0d046bdb8a77",
   "metadata": {},
   "source": [
    "## 4.1 Data Split\n",
    "\n",
    "We split data to training data set and testing dataset based on date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9ac751-d5fd-44b3-b137-1402e11ce5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train-validate-test split proportions ###\n",
    "\n",
    "select_dates = []\n",
    "test_dates = []\n",
    "\n",
    "for i in range(0,len(dates)):\n",
    "    if i % 5 != 0:\n",
    "        select_dates.append(dates[i]) ### 80% train days set ###\n",
    "    if i % 5 == 0:\n",
    "        test_dates.append(dates[i]) ### 20% test days set ### \n",
    "\n",
    "### Then, the month numbers above are converted back to their respective datetime objects.\n",
    "\n",
    "year_mon = []\n",
    "\n",
    "for i in range(0,len(select_dates)):\n",
    "    \n",
    "    tmp = select_dates[i]\n",
    "    year_mon.append(f\"{tmp.year}-{tmp.month}\")\n",
    "    \n",
    "test_year_mon = []\n",
    "\n",
    "for i in range(0,len(test_dates)):\n",
    "    \n",
    "    tmp = test_dates[i]\n",
    "    test_year_mon.append(f\"{tmp.year}-{tmp.month}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c92ad9-b5c1-478c-95e3-1e1383de39b5",
   "metadata": {},
   "source": [
    "## 4.2 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d1c3160-bd76-46fc-a099-dc27add89ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "__SEED__ = 10\n",
    "torch.manual_seed(__SEED__)\n",
    "\n",
    "if Models(__MODEL_TYPE__) == Models.NEURAL_NETWORK:\n",
    "    params = {\n",
    "        'input_nodes':13,\n",
    "        'hidden_nodes':50,\n",
    "        'output_nodes':1,\n",
    "        'epochs':3000,\n",
    "        'lr': 1e-03\n",
    "    }\n",
    "elif Models(__MODEL_TYPE__) == Models.XGBOOST:\n",
    "    params = {\n",
    "        'n_estimators': 500,  # Number of boosting rounds\n",
    "        'max_depth': 6,  # Maximum depth of each tree to control model complexity\n",
    "        'learning_rate': 0.05,  # Step size shrinkage to prevent overfitting\n",
    "        'subsample': 0.8,  # Fraction of samples used for training each tree\n",
    "        'colsample_bytree': 0.8,  # Fraction of features used per tree\n",
    "        'gamma': 0.1,  # Minimum loss reduction required for further partitioning\n",
    "        'min_child_weight': 5,  # Minimum sum of instance weight in a leaf node\n",
    "        'reg_alpha': 0.1,  # L1 regularization to reduce model complexity\n",
    "        'reg_lambda': 1.0,  # L2 regularization for preventing overfitting\n",
    "        'objective': 'reg:squarederror',  # Loss function for regression tasks\n",
    "        'n_jobs': 30,  # Number of parallel threads to use for training\n",
    "        'eval_metric': 'rmse',\n",
    "        'early_stopping_rounds': 50  # Stop training if performance doesn't improve for 50 rounds\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(f\"model {__MODEL_TYPE__} not supported! Please choose a model in [`{Models.NEURAL_NETWORK.value}`, `{Models.XGBOOST.value}`]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d0e20-666e-46b0-9ae6-fa7b3e40f5e3",
   "metadata": {},
   "source": [
    "### Important Note: Run ML (4.3) and Reconstruction (4.4) Part Only Once\n",
    "\n",
    "The **ML Reconstruction** step needs to be run **only once** for each ML model developed. This helps save computational resources and execution time.\n",
    "\n",
    "The reconstruction data is saved under our **own username-specific workspace** in GCS. This means that even if you exit and re-enter JupyterHub, your data will remain available, eliminating the need for reprocessing.\n",
    "\n",
    "### Before Running Again:\n",
    "Before re-running the ML training steps, make sure a new experiment is actually necessary. Avoiding redundant computations helps optimize time and resource usage. It's also a good idea to monitor your storage regularly and clean up unnecessary files. If you're certain that no new experiment is needed, you can comment out the relevant code (set runthiscell = \"0\") to prevent accidental re-execution.\n",
    "\n",
    "For reviewer, set runthiscell to -1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f267d8-fe61-41f4-a7e4-593f1f18d478",
   "metadata": {},
   "source": [
    "## ML train/val/test data\n",
    "The ML model was trained on **masked synthetic data** that mimics real-world observational sampling patterns (SOCAT). Specifically, for each ensemble member, we:\n",
    "\n",
    "1. **Filtered valid samples** by selecting grid cells that have:\n",
    "   - No missing values in input features or the target (`pCO₂-Residual`),\n",
    "   - Physically realistic `pCO₂-Residual` values (between -250 and 250 μatm),\n",
    "   - An ocean mask indicating valid ocean regions.\n",
    "\n",
    "2. **Identified SOCAT-like samples** using a binary `socat_mask`.  \n",
    "   - We defined the **training pool** as grid cells where **`socat_mask == 1`**, and the time falls within a list of pre-selected training months (`year_mon`).\n",
    "   - Similarly, **testing data** was drawn from SOCAT-like samples falling into the `test_year_mon` time range.\n",
    "\n",
    "3. **Performed a secondary train/val split** (within the training pool) using a stratified random seed matrix (`random_seeds`), where the seed location is tied to each ensemble member to ensure reproducibility and model diversity across members.\n",
    "\n",
    "4. The **“unseen” data**, i.e., where **`socat_mask == 0`** but data is otherwise valid, was reserved for reconstruction evaluation in non-observed regions.\n",
    "\n",
    "This ensures that:\n",
    "- Training and testing sets do **not overlap in time** (`year_mon` vs. `test_year_mon`),\n",
    "- And are drawn from the same spatial sampling mask, preserving the real-world SOCAT sampling pattern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe56c2a9-7e31-4135-927a-df32ff612c1e",
   "metadata": {},
   "source": [
    "## 4.3 ML Training\n",
    "\n",
    "To avoid re-run the ML training, set runthiscell = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "841b065b-ed58-471f-8ed2-bc3311325555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-23 00:39:51.215014\n",
      "ACCESS-ESM1-5 member_r10i1p1f1\n",
      "Starting local model saving process...\n",
      "Model successfully saved locally at: output/model_saved/model_pCO2_2D_ACCESS-ESM1-5_r10i1p1f1_mon_1x1_200401_202312.json\n",
      "Local model saving process complete.\n",
      "test performance metrics: {'mse': 42.438170596002145, 'mae': 4.384799247535554, 'medae': np.float64(3.013752960771411), 'max_error': np.float64(97.43568815344298), 'bias': np.float64(-0.17627704089943386), 'r2': 0.9154561067344921, 'corr': np.float64(0.9576685617898728), 'cent_rmse': np.float64(6.512073132565073), 'stdev': np.float32(20.556904), 'amp_ratio': np.float64(0.8132994779850793), 'stdev_ref': np.float64(22.404600558721125), 'range_ref': np.float64(320.75740023610456), 'iqr_ref': np.float64(25.555605155883118)}\n",
      "ACCESS-ESM1-5 member_r5i1p1f1\n",
      "Starting local model saving process...\n",
      "Model successfully saved locally at: output/model_saved/model_pCO2_2D_ACCESS-ESM1-5_r5i1p1f1_mon_1x1_200401_202312.json\n",
      "Local model saving process complete.\n",
      "test performance metrics: {'mse': 42.28539676083253, 'mae': 4.383689411478896, 'medae': np.float64(3.028169419441655), 'max_error': np.float64(87.01500046546187), 'bias': np.float64(-0.24462014137070653), 'r2': 0.9186501523014686, 'corr': np.float64(0.9595048882407627), 'cent_rmse': np.float64(6.498119592222762), 'stdev': np.float32(20.886114), 'amp_ratio': np.float64(0.872969023620373), 'stdev_ref': np.float64(22.799054295901502), 'range_ref': np.float64(342.194873838101), 'iqr_ref': np.float64(26.826667918076367)}\n",
      "ACCESS-ESM1-5 member_r2i1p1f1\n",
      "Starting local model saving process...\n",
      "Model successfully saved locally at: output/model_saved/model_pCO2_2D_ACCESS-ESM1-5_r2i1p1f1_mon_1x1_200401_202312.json\n",
      "Local model saving process complete.\n",
      "test performance metrics: {'mse': 42.21578525282436, 'mae': 4.402892546598675, 'medae': np.float64(3.0241036997461634), 'max_error': np.float64(76.03767249884919), 'bias': np.float64(-0.02798790032200671), 'r2': 0.9203435234883338, 'corr': np.float64(0.9600139065259552), 'cent_rmse': np.float64(6.497307318850442), 'stdev': np.float32(21.276442), 'amp_ratio': np.float64(0.81503628645322), 'stdev_ref': np.float64(23.021143390719143), 'range_ref': np.float64(322.47657314293525), 'iqr_ref': np.float64(26.37736593005285)}\n",
      "CanESM5 member_r2i1p1f1\n",
      "Starting local model saving process...\n",
      "Model successfully saved locally at: output/model_saved/model_pCO2_2D_CanESM5_r2i1p1f1_mon_1x1_200401_202312.json\n",
      "Local model saving process complete.\n",
      "test performance metrics: {'mse': 26.619111410128504, 'mae': 3.493869089859, 'medae': np.float64(2.4446541590018285), 'max_error': np.float64(63.19070825096643), 'bias': np.float64(-0.1729225226000839), 'r2': 0.8886285597496303, 'corr': np.float64(0.9433062850193745), 'cent_rmse': np.float64(5.156472568212857), 'stdev': np.float32(14.07709), 'amp_ratio': np.float64(0.8028610169818607), 'stdev_ref': np.float64(15.460013149465423), 'range_ref': np.float64(232.22932990004043), 'iqr_ref': np.float64(19.291121566950267)}\n",
      "CanESM5 member_r1i1p2f1\n",
      "Starting local model saving process...\n",
      "Model successfully saved locally at: output/model_saved/model_pCO2_2D_CanESM5_r1i1p2f1_mon_1x1_200401_202312.json\n",
      "Local model saving process complete.\n",
      "test performance metrics: {'mse': 27.995820357991523, 'mae': 3.6284926527400714, 'medae': np.float64(2.5429877964871324), 'max_error': np.float64(67.86115266451257), 'bias': np.float64(-0.332320812691), 'r2': 0.8903689889955817, 'corr': np.float64(0.9442808751998506), 'cent_rmse': np.float64(5.280661302801091), 'stdev': np.float32(14.61975), 'amp_ratio': np.float64(0.821910819066162), 'stdev_ref': np.float64(15.980114599361855), 'range_ref': np.float64(270.26526053370924), 'iqr_ref': np.float64(20.341248155881956)}\n",
      "CanESM5 member_r1i1p1f1\n",
      "Starting local model saving process...\n",
      "Model successfully saved locally at: output/model_saved/model_pCO2_2D_CanESM5_r1i1p1f1_mon_1x1_200401_202312.json\n",
      "Local model saving process complete.\n",
      "test performance metrics: {'mse': 25.518582556843413, 'mae': 3.461047899459184, 'medae': np.float64(2.4650866365931545), 'max_error': np.float64(79.69439156669915), 'bias': np.float64(-0.2260299831303474), 'r2': 0.900482794316636, 'corr': np.float64(0.9495589236348884), 'cent_rmse': np.float64(5.0465327563158775), 'stdev': np.float32(14.704191), 'amp_ratio': np.float64(0.7420480091398984), 'stdev_ref': np.float64(16.013239060949285), 'range_ref': np.float64(256.95487247989155), 'iqr_ref': np.float64(20.702463842127166)}\n",
      "MPI-ESM1-2-LR member_r12i1p1f1\n",
      "Starting local model saving process...\n",
      "Model successfully saved locally at: output/model_saved/model_pCO2_2D_MPI-ESM1-2-LR_r12i1p1f1_mon_1x1_200401_202312.json\n",
      "Local model saving process complete.\n",
      "test performance metrics: {'mse': 49.39683313171356, 'mae': 4.764274599993918, 'medae': np.float64(3.3962287170069123), 'max_error': np.float64(150.08872440783873), 'bias': np.float64(-0.335580483289462), 'r2': 0.9473036503875646, 'corr': np.float64(0.9739113051866164), 'cent_rmse': np.float64(7.0202719746896385), 'stdev': np.float32(28.812103), 'amp_ratio': np.float64(0.8448315739252797), 'stdev_ref': np.float64(30.616764068504423), 'range_ref': np.float64(376.1060626310961), 'iqr_ref': np.float64(34.607478910151535)}\n",
      "MPI-ESM1-2-LR member_r11i1p1f1\n",
      "Starting local model saving process...\n",
      "Model successfully saved locally at: output/model_saved/model_pCO2_2D_MPI-ESM1-2-LR_r11i1p1f1_mon_1x1_200401_202312.json\n",
      "Local model saving process complete.\n",
      "test performance metrics: {'mse': 52.06351075530385, 'mae': 4.847942931202115, 'medae': np.float64(3.414235923072991), 'max_error': np.float64(136.49903625814716), 'bias': np.float64(-0.1979829254660146), 'r2': 0.9449611395611214, 'corr': np.float64(0.9728092497525117), 'cent_rmse': np.float64(7.21278818667639), 'stdev': np.float32(28.787615), 'amp_ratio': np.float64(0.8084570654426707), 'stdev_ref': np.float64(30.756152695817217), 'range_ref': np.float64(390.14279146210157), 'iqr_ref': np.float64(35.14591789279477)}\n",
      "MPI-ESM1-2-LR member_r15i1p1f1\n",
      "Starting local model saving process...\n",
      "Model successfully saved locally at: output/model_saved/model_pCO2_2D_MPI-ESM1-2-LR_r15i1p1f1_mon_1x1_200401_202312.json\n",
      "Local model saving process complete.\n",
      "test performance metrics: {'mse': 47.82046287028598, 'mae': 4.66314929163724, 'medae': np.float64(3.2768917804019253), 'max_error': np.float64(137.42661300762956), 'bias': np.float64(-0.31709220670781235), 'r2': 0.947719529919878, 'corr': np.float64(0.9739818430096105), 'cent_rmse': np.float64(6.907960290819089), 'stdev': np.float32(28.595587), 'amp_ratio': np.float64(0.8091041651535823), 'stdev_ref': np.float64(30.243854900229472), 'range_ref': np.float64(376.1950494810957), 'iqr_ref': np.float64(34.57425593091518)}\n",
      "end of all members 2025-04-23 00:47:03.105936\n"
     ]
    }
   ],
   "source": [
    "runthiscell = 1  # 0 will turn off, 1 will turn on, -1 will only run the first member. Reviewers should set this to -1.\n",
    "\n",
    "if runthiscell:  \n",
    "    \n",
    "    seed_loc_dict = defaultdict(dict)\n",
    "    for ens,mem_list in mems_dict.items():\n",
    "        sub_dictt = dict()\n",
    "        for no,mem in enumerate(mem_list):\n",
    "            sub_dictt.update({mem:no})\n",
    "        seed_loc_dict.update({ens:sub_dictt})\n",
    "\n",
    "    if runthiscell == -1:\n",
    "        print(\"Reviewing process: Running ML only for the first member of the first ESM.\")\n",
    "        first_ens = list(selected_mems_dict.keys())[0]  # Get the first ensemble key\n",
    "        first_mem = selected_mems_dict[first_ens][0]   # Get the first member in that ensemble\n",
    "        run_selected_mems_dict = {first_ens: [first_mem]}  # Create a dictionary with only the first ensemble and member\n",
    "    else:\n",
    "        run_selected_mems_dict = selected_mems_dict\n",
    "    \n",
    "    train_member_models(\n",
    "        saving_paths=saving_paths,\n",
    "        features=features_sel,\n",
    "        target=target_sel,\n",
    "        train_year_mon=year_mon,\n",
    "        test_year_mon=test_year_mon,\n",
    "        run_selected_mems_dict=run_selected_mems_dict,\n",
    "        seed_loc_dict=seed_loc_dict,\n",
    "        dates=dates,\n",
    "        model_type=__MODEL_TYPE__,\n",
    "        is_training=True,\n",
    "        **params\n",
    "    )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2fe26b-5ed1-4f35-b225-5f084bddbead",
   "metadata": {},
   "source": [
    "## 4.4 Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd31b2-96e8-47aa-a5de-bbbd01c02411",
   "metadata": {},
   "source": [
    "### What Are We Reconstructing?\n",
    "\n",
    "After training the model, we generate pCO₂ predictions not just for evaluation but also for reconstructing spatial fields across different sample categories:\n",
    "\n",
    "1. **`unseen_sel`**: These are grid points that are valid (no missing values, within physical bounds) but **not observed** in the SOCAT dataset (i.e., `socat_mask == 0`). Predictions on these samples (`y_pred_unseen`) test the model’s ability to generalize beyond observed regions.\n",
    "\n",
    "2. **`sel`**: These are SOCAT-like samples where `socat_mask == 1`. They include both training and test data (depending on the year/month). Predictions here (`y_pred_seen`) are used to assess performance where observations exist.\n",
    "\n",
    "\n",
    "### Explanation of Reconstruction Output Variables\n",
    "\n",
    "Each column added to the DataFrame (`df`) serves a specific purpose in evaluation and reconstruction:\n",
    "\n",
    "| Variable | Description |\n",
    "|----------|-------------|\n",
    "| `pCO2_truth` | The actual pCO₂ residual values|\n",
    "| `pCO2_recon_full` | The full reconstruction result (predicted values across both SOCAT and unseen regions). |\n",
    "| `pCO2_recon_unseen` | Predicted values only for unseen regions (where `socat_mask == 0`). |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732161a2-6b0d-4266-b79d-ff0eeaee9324",
   "metadata": {},
   "source": [
    "If you have not changed your ML, the reconstruction step (~1 minute/member) does not need to be re-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38990cc7-f40c-44a2-a70c-5e5615d74b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-23 00:47:03.208570\n",
      "ACCESS-ESM1-5 member_r10i1p1f1\n",
      "loading model...\n",
      "Starting reconstruction saving process\n",
      "gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/ACCESS-ESM1-5/member_r10i1p1f1/recon_pCO2residual_ACCESS-ESM1-5_member_r10i1p1f1_mon_1x1_200401_202312.zarr\n",
      "Save complete\n",
      "unseen performance metrics: {'mse': 78.85023941487994, 'mae': 5.755844568911232, 'medae': np.float64(3.882621632254125), 'max_error': np.float64(205.94291012613428), 'bias': np.float64(-0.09608445098090179), 'r2': 0.8630529463382421, 'corr': np.float64(0.9305539489154622), 'cent_rmse': np.float64(8.879245863034992), 'stdev': np.float32(21.045254), 'amp_ratio': np.float64(0.737706106993398), 'stdev_ref': np.float64(23.995243509600023), 'range_ref': np.float64(442.229265014214), 'iqr_ref': np.float64(27.310390035211178)}\n",
      "ACCESS-ESM1-5 member_r5i1p1f1\n",
      "loading model...\n",
      "Starting reconstruction saving process\n",
      "gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/ACCESS-ESM1-5/member_r5i1p1f1/recon_pCO2residual_ACCESS-ESM1-5_member_r5i1p1f1_mon_1x1_200401_202312.zarr\n",
      "Save complete\n",
      "unseen performance metrics: {'mse': 80.22812485860207, 'mae': 5.749073981100572, 'medae': np.float64(3.865366237239283), 'max_error': np.float64(217.1573192500307), 'bias': np.float64(0.011528951009612598), 'r2': 0.864081794739139, 'corr': np.float64(0.9311359645630144), 'cent_rmse': np.float64(8.957007953134147), 'stdev': np.float32(21.306763), 'amp_ratio': np.float64(0.7836638232510555), 'stdev_ref': np.float64(24.295425260828683), 'range_ref': np.float64(425.89847912607524), 'iqr_ref': np.float64(28.346007927619524)}\n",
      "ACCESS-ESM1-5 member_r2i1p1f1\n",
      "loading model...\n",
      "Starting reconstruction saving process\n",
      "gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/ACCESS-ESM1-5/member_r2i1p1f1/recon_pCO2residual_ACCESS-ESM1-5_member_r2i1p1f1_mon_1x1_200401_202312.zarr\n",
      "Save complete\n",
      "unseen performance metrics: {'mse': 79.56187680779487, 'mae': 5.766363776988565, 'medae': np.float64(3.898335379810389), 'max_error': np.float64(220.32375309570722), 'bias': np.float64(-0.009368164108726873), 'r2': 0.8630745278231775, 'corr': np.float64(0.9304429623728157), 'cent_rmse': np.float64(8.919741558480801), 'stdev': np.float32(21.187733), 'amp_ratio': np.float64(0.6814523582714198), 'stdev_ref': np.float64(24.105180399099225), 'range_ref': np.float64(425.5021031207644), 'iqr_ref': np.float64(27.52578002423216)}\n",
      "CanESM5 member_r2i1p1f1\n",
      "loading model...\n",
      "Starting reconstruction saving process\n",
      "gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/CanESM5/member_r2i1p1f1/recon_pCO2residual_CanESM5_member_r2i1p1f1_mon_1x1_200401_202312.zarr\n",
      "Save complete\n",
      "unseen performance metrics: {'mse': 57.704161193496475, 'mae': 4.933800145935021, 'medae': np.float64(3.3342604115341117), 'max_error': np.float64(226.31481040934037), 'bias': np.float64(0.056267933904944556), 'r2': 0.7965142309487842, 'corr': np.float64(0.8930664681702154), 'cent_rmse': np.float64(7.5961170933581235), 'stdev': np.float32(14.495381), 'amp_ratio': np.float64(0.572085149578703), 'stdev_ref': np.float64(16.839785110514534), 'range_ref': np.float64(489.2478307873397), 'iqr_ref': np.float64(20.621666038243426)}\n",
      "CanESM5 member_r1i1p2f1\n",
      "loading model...\n",
      "Starting reconstruction saving process\n",
      "gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/CanESM5/member_r1i1p2f1/recon_pCO2residual_CanESM5_member_r1i1p2f1_mon_1x1_200401_202312.zarr\n",
      "Save complete\n",
      "unseen performance metrics: {'mse': 60.60387104149166, 'mae': 5.071130662970676, 'medae': np.float64(3.4385395144667186), 'max_error': np.float64(210.60242484772698), 'bias': np.float64(-0.1316175648729736), 'r2': 0.797151277722426, 'corr': np.float64(0.8939845135861186), 'cent_rmse': np.float64(7.783736249430075), 'stdev': np.float32(14.679511), 'amp_ratio': np.float64(0.5530824647643481), 'stdev_ref': np.float64(17.28478749142178), 'range_ref': np.float64(485.1507437592543), 'iqr_ref': np.float64(21.528754864160163)}\n",
      "CanESM5 member_r1i1p1f1\n",
      "loading model...\n",
      "Starting reconstruction saving process\n",
      "gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/CanESM5/member_r1i1p1f1/recon_pCO2residual_CanESM5_member_r1i1p1f1_mon_1x1_200401_202312.zarr\n",
      "Save complete\n",
      "unseen performance metrics: {'mse': 57.40117512366588, 'mae': 4.966559656500763, 'medae': np.float64(3.4115909844511707), 'max_error': np.float64(203.09132962039956), 'bias': np.float64(-0.038334102732447306), 'r2': 0.8120122117131552, 'corr': np.float64(0.9017974021358302), 'cent_rmse': np.float64(7.576259416090081), 'stdev': np.float32(15.147391), 'amp_ratio': np.float64(0.5144989519049121), 'stdev_ref': np.float64(17.47413040968989), 'range_ref': np.float64(463.80917320157414), 'iqr_ref': np.float64(22.106285788963245)}\n",
      "MPI-ESM1-2-LR member_r12i1p1f1\n",
      "loading model...\n",
      "Starting reconstruction saving process\n",
      "gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/MPI-ESM1-2-LR/member_r12i1p1f1/recon_pCO2residual_MPI-ESM1-2-LR_member_r12i1p1f1_mon_1x1_200401_202312.zarr\n",
      "Save complete\n",
      "unseen performance metrics: {'mse': 101.97259964860419, 'mae': 6.779125987645236, 'medae': np.float64(4.771583214270989), 'max_error': np.float64(235.10343867659333), 'bias': np.float64(-0.4622300630642542), 'r2': 0.909705220899558, 'corr': np.float64(0.954348099459354), 'cent_rmse': np.float64(10.08756393031717), 'stdev': np.float32(31.071125), 'amp_ratio': np.float64(0.7383181159635884), 'stdev_ref': np.float64(33.60550496862352), 'range_ref': np.float64(469.5892330103237), 'iqr_ref': np.float64(36.794755453001855)}\n",
      "MPI-ESM1-2-LR member_r11i1p1f1\n",
      "loading model...\n",
      "Starting reconstruction saving process\n",
      "gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/MPI-ESM1-2-LR/member_r11i1p1f1/recon_pCO2residual_MPI-ESM1-2-LR_member_r11i1p1f1_mon_1x1_200401_202312.zarr\n",
      "Save complete\n",
      "unseen performance metrics: {'mse': 108.37169715609649, 'mae': 6.994596903818793, 'medae': np.float64(4.875240080203058), 'max_error': np.float64(242.06582166771068), 'bias': np.float64(-0.7164801675871146), 'r2': 0.906016867340222, 'corr': np.float64(0.9528334939777686), 'cent_rmse': np.float64(10.385486918795639), 'stdev': np.float32(31.071712), 'amp_ratio': np.float64(0.7609335031029578), 'stdev_ref': np.float64(33.957286505487176), 'range_ref': np.float64(464.81230254656475), 'iqr_ref': np.float64(37.488078807961685)}\n",
      "MPI-ESM1-2-LR member_r15i1p1f1\n",
      "loading model...\n",
      "Starting reconstruction saving process\n",
      "gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/MPI-ESM1-2-LR/member_r15i1p1f1/recon_pCO2residual_MPI-ESM1-2-LR_member_r15i1p1f1_mon_1x1_200401_202312.zarr\n",
      "Save complete\n",
      "unseen performance metrics: {'mse': 101.16723736468784, 'mae': 6.769688628978266, 'medae': np.float64(4.755942233241367), 'max_error': np.float64(229.66075246092782), 'bias': np.float64(-0.6697719528547097), 'r2': 0.9090751709862814, 'corr': np.float64(0.9540789241365782), 'cent_rmse': np.float64(10.035867660407776), 'stdev': np.float32(30.88811), 'amp_ratio': np.float64(0.7401252721270657), 'stdev_ref': np.float64(33.356363568430424), 'range_ref': np.float64(461.39357356091716), 'iqr_ref': np.float64(36.72313270403645)}\n",
      "end of all members 2025-04-23 01:06:05.947799\n"
     ]
    }
   ],
   "source": [
    "runthiscell = 1  # 0 will turn off, 1 will turn on, -1 will only run the first member. Reviewers should set this to -1.\n",
    "\n",
    "if runthiscell:\n",
    "\n",
    "    if runthiscell == -1:\n",
    "        print(\"Reviewing process: Running reconstrunction only for the first member of the first ESM.\")\n",
    "        first_ens = list(selected_mems_dict.keys())[0]  # Get the first ensemble key\n",
    "        first_mem = selected_mems_dict[first_ens][0]   # Get the first member in that ensemble\n",
    "        run_selected_mems_dict = {first_ens: [first_mem]}  # Create a dictionary with only the first ensemble and member\n",
    "    else:\n",
    "        run_selected_mems_dict = selected_mems_dict\n",
    "\n",
    "    train_member_models(\n",
    "        saving_paths=saving_paths,\n",
    "        features=features_sel,\n",
    "        target=target_sel,\n",
    "        train_year_mon=year_mon,\n",
    "        test_year_mon=test_year_mon,\n",
    "        run_selected_mems_dict=run_selected_mems_dict,\n",
    "        seed_loc_dict=seed_loc_dict,\n",
    "        dates=dates,\n",
    "        model_type=__MODEL_TYPE__,\n",
    "        is_training=False,\n",
    "        **params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e46b5-96a1-4838-841a-cced36a81ee7",
   "metadata": {},
   "source": [
    "### 4.4.1 Add pCO2-seasonal + pCO2-deseasonal + pCO2-Temperature back to reconstructed pCO2-Residual, thus recovering pCO2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4348efb7-7609-4968-87b7-ca7037620fca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current ESM: ACCESS-ESM1-5\n",
      "On member member_r10i1p1f1\n",
      "pco2T path: gs://leap-persistent/abbysh/pco2_all_members_1982-2023/00_regridded_members/ACCESS-ESM1-5/member_r10i1p1f1/ACCESS-ESM1-5.r10i1p1f1.Omon.zarr\n",
      "pCO2R XGBoost path:gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/ACCESS-ESM1-5/member_r10i1p1f1/recon_pCO2residual_ACCESS-ESM1-5_member_r10i1p1f1_mon_1x1_200401_202312.zarr\n",
      "pCO2R NeuralNetwork path:gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_nn/reconstructions/ACCESS-ESM1-5/member_r10i1p1f1/recon_pCO2residual_ACCESS-ESM1-5_member_r10i1p1f1_mon_1x1_200401_202312.zarr\n",
      "save path: gs://leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_xgb/reconstructions/ACCESS-ESM1-5/member_r10i1p1f1/recon_pCO2_ACCESS-ESM1-5_member_r10i1p1f1_mon_1x1_200401_202312.zarr\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find group: <FsspecStore(GCSFileSystem, leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_nn/reconstructions/ACCESS-ESM1-5/member_r10i1p1f1/recon_pCO2residual_ACCESS-ESM1-5_member_r10i1p1f1_mon_1x1_200401_202312.zarr)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     supporting_functions\u001b[38;5;241m.\u001b[39mcalc_recon_pco2_modified(saving_paths\u001b[38;5;241m.\u001b[39mensemble_dir, saving_paths\u001b[38;5;241m.\u001b[39mrecon_output_dir, saving_paths\u001b[38;5;241m.\u001b[39mrecon_output_dir_alternate, selected_mems_dict, init_date, fin_date, owner_username)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43msupporting_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_recon_pco2_modified\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaving_paths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensemble_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaving_paths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecon_output_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaving_paths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecon_output_dir_alternate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_mems_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfin_date\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/climate-ml-project3-group2/Project3-ReconstructPCO2/lib/residual_utils.py:1122\u001b[0m, in \u001b[0;36mcalc_recon_pco2_modified\u001b[0;34m(regridded_members_dir, pco2_recon_dir_xgb, pco2_recon_dir_nn, selected_mems_dict, init_date, fin_date, owner_name)\u001b[0m\n\u001b[1;32m   1120\u001b[0m pco2T_series \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_zarr(pco2T_path)\u001b[38;5;241m.\u001b[39mpco2_T\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mylat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlon\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(init_date_sel, fin_date_sel))\n\u001b[1;32m   1121\u001b[0m pco2_ml_output_xgb \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_zarr(pCO2R_path_xgb) \u001b[38;5;66;03m#, consolidated=False, storage_options={\"token\": \"cloud\"}, group=None)\u001b[39;00m\n\u001b[0;32m-> 1122\u001b[0m pco2_ml_output_nn \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpCO2R_path_nn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m### unseen reconstructed pCO2-Residual from XGB\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m pCO2R_unseen_series_xgb \u001b[38;5;241m=\u001b[39m pco2_ml_output_xgb\u001b[38;5;241m.\u001b[39mpCO2_recon_unseen\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mylat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlon\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/backends/zarr.py:1491\u001b[0m, in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, zarr_format, use_zarr_fill_value_as_mask, chunked_array_type, from_array_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopen_zarr() got unexpected keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(kwargs\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   1479\u001b[0m     )\n\u001b[1;32m   1481\u001b[0m backend_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1482\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynchronizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: synchronizer,\n\u001b[1;32m   1483\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsolidated\u001b[39m\u001b[38;5;124m\"\u001b[39m: consolidated,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzarr_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: zarr_format,\n\u001b[1;32m   1489\u001b[0m }\n\u001b[0;32m-> 1491\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_cf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_cf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_and_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_characters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzarr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked_array_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_timedelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/backends/api.py:679\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    668\u001b[0m     decode_cf,\n\u001b[1;32m    669\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    675\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    676\u001b[0m )\n\u001b[1;32m    678\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 679\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    686\u001b[0m     backend_ds,\n\u001b[1;32m    687\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    698\u001b[0m )\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/backends/zarr.py:1564\u001b[0m, in \u001b[0;36mZarrBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, zarr_version, zarr_format, store, engine, use_zarr_fill_value_as_mask, cache_members)\u001b[0m\n\u001b[1;32m   1562\u001b[0m filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m store:\n\u001b[0;32m-> 1564\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mZarrStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_members\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_members\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1579\u001b[0m store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/backends/zarr.py:703\u001b[0m, in \u001b[0;36mZarrStore.open_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, zarr_version, zarr_format, use_zarr_fill_value_as_mask, write_empty, cache_members)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopen_group\u001b[39m(\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    696\u001b[0m     cache_members: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    697\u001b[0m ):\n\u001b[1;32m    698\u001b[0m     (\n\u001b[1;32m    699\u001b[0m         zarr_group,\n\u001b[1;32m    700\u001b[0m         consolidate_on_close,\n\u001b[1;32m    701\u001b[0m         close_store_on_close,\n\u001b[1;32m    702\u001b[0m         use_zarr_fill_value_as_mask,\n\u001b[0;32m--> 703\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_open_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    718\u001b[0m         zarr_group,\n\u001b[1;32m    719\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    727\u001b[0m         cache_members,\n\u001b[1;32m    728\u001b[0m     )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/backends/zarr.py:1761\u001b[0m, in \u001b[0;36m_get_open_params\u001b[0;34m(store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, zarr_version, use_zarr_fill_value_as_mask, zarr_format)\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidated \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1760\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1761\u001b[0m         zarr_group \u001b[38;5;241m=\u001b[39m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_consolidated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[1;32m   1763\u001b[0m         \u001b[38;5;66;03m# ValueError in zarr-python 3.x, KeyError in 2.x.\u001b[39;00m\n\u001b[1;32m   1764\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/api/synchronous.py:212\u001b[0m, in \u001b[0;36mopen_consolidated\u001b[0;34m(use_consolidated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopen_consolidated\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, use_consolidated: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Group:\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    Alias for :func:`open_group` with ``use_consolidated=True``.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Group(\n\u001b[0;32m--> 212\u001b[0m         \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_consolidated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_consolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_consolidated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m     )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/core/sync.py:142\u001b[0m, in \u001b[0;36msync\u001b[0;34m(coro, loop, timeout)\u001b[0m\n\u001b[1;32m    139\u001b[0m return_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(finished))\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/core/sync.py:98\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03mAwait a coroutine and return the result of running it. If awaiting the coroutine raises an\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mexception, the exception will be returned.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ex\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/api/asynchronous.py:346\u001b[0m, in \u001b[0;36mopen_consolidated\u001b[0;34m(use_consolidated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_consolidated \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_consolidated\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen_consolidated\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_consolidated=False\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to bypass consolidated metadata.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m     )\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m open_group(\u001b[38;5;241m*\u001b[39margs, use_consolidated\u001b[38;5;241m=\u001b[39muse_consolidated, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/zarr/api/asynchronous.py:821\u001b[0m, in \u001b[0;36mopen_group\u001b[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, zarr_format, meta_array, attributes, use_consolidated)\u001b[0m\n\u001b[1;32m    814\u001b[0m     _zarr_format \u001b[38;5;241m=\u001b[39m zarr_format \u001b[38;5;129;01mor\u001b[39;00m _default_zarr_format()\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m AsyncGroup\u001b[38;5;241m.\u001b[39mfrom_store(\n\u001b[1;32m    816\u001b[0m         store_path,\n\u001b[1;32m    817\u001b[0m         zarr_format\u001b[38;5;241m=\u001b[39m_zarr_format,\n\u001b[1;32m    818\u001b[0m         overwrite\u001b[38;5;241m=\u001b[39moverwrite,\n\u001b[1;32m    819\u001b[0m         attributes\u001b[38;5;241m=\u001b[39mattributes,\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find group: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstore_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find group: <FsspecStore(GCSFileSystem, leap-persistent/JuanPalaciosGodoy/JuanPalaciosGodoy/pco2_residual/nmse/post02_nn/reconstructions/ACCESS-ESM1-5/member_r10i1p1f1/recon_pCO2residual_ACCESS-ESM1-5_member_r10i1p1f1_mon_1x1_200401_202312.zarr)>"
     ]
    }
   ],
   "source": [
    "runthiscell = 1  # 0 will turn off, 1 will turn on\n",
    "\n",
    "if runthiscell:\n",
    "    if runthiscell == -1:\n",
    "        supporting_functions.calc_recon_pco2_modified(saving_paths.ensemble_dir, saving_paths.recon_output_dir, saving_paths.recon_output_dir_alternate, selected_mems_dict, init_date, fin_date, owner_username)\n",
    "    else:\n",
    "        supporting_functions.calc_recon_pco2_modified(saving_paths.ensemble_dir, saving_paths.recon_output_dir, saving_paths.recon_output_dir_alternate, selected_mems_dict, init_date, fin_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b62ad4-4442-409f-b818-b42be3a3dbb4",
   "metadata": {},
   "source": [
    "**For the owner who completed the experiment and reconstructed the data:**\n",
    "\n",
    "1. Ensure that the reconstruction data you saved under the specified path is clean, accurate, and ready for sharing.\n",
    "2. Only the data you wish to save and provide to reviewers should be kept.\n",
    "3. Change the permissions to allow others to read the data, ensuring it's accessible to reviewers.\n",
    "\n",
    "\n",
    "**Reviewers should not run this cell**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74cb4dd-d141-45b0-a782-780e7eb376a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "if runthiscell != -1:\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(\"leap-persistent\")\n",
    "    \n",
    "    prefix = f\"{owner_username}/{owner_username}/pco2_residual/nmse/post02_xgb/reconstructions/\"\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    \n",
    "    seen_dirs = set()  # Track top-level directories (immediate subdirectories of `reconstructions`)\n",
    "\n",
    "    for blob in blobs:\n",
    "        # Extract the relative path after `reconstructions/`\n",
    "        relative_path = blob.name[len(prefix):]\n",
    "        top_level_dir = relative_path.split(\"/\")[0]  # Get first component\n",
    "\n",
    "        try:\n",
    "            # Make the file public\n",
    "            blob.make_public()\n",
    "            \n",
    "            # Only print if it's a new top-level directory\n",
    "            if top_level_dir not in seen_dirs:\n",
    "                seen_dirs.add(top_level_dir)\n",
    "                print(f\"Made public: {top_level_dir}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to make public: {blob.name}\")\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6674a86-9b05-4234-9475-c8ad54a8539e",
   "metadata": {},
   "source": [
    "###  4.4.3  Visualize the reconstruction for 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602feb8-a0e5-4b22-bd9f-221451d871b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "plot_style = \"seaborn-v0_8-talk\"\n",
    "cmap = cm.cm.thermal\n",
    "cbar_title = 'pCO₂ (µatm)'\n",
    "vrange = [280, 440]  # Colorbar range\n",
    "\n",
    "# Select the first ensemble and member from the dictionary\n",
    "first_ens = list(selected_mems_dict.keys())[0]\n",
    "first_mem = selected_mems_dict[first_ens][0]\n",
    "\n",
    "# Load original member data from ESM output\n",
    "member_dir = f\"{saving_paths.ensemble_dir}/{first_ens}/{first_mem}\"\n",
    "member_path = fs.glob(f\"{member_dir}/*.zarr\")[0]\n",
    "# member_data = xr.open_mfdataset('gs://' + member_path, engine='zarr').sel(time=slice(str(dates[0]), str(dates[-1])))\n",
    "member_data = xr.open_zarr('gs://' + member_path).sel(time=slice(str(dates[0]), str(dates[-1])))\n",
    "\n",
    "# Load reconstructed pCO₂ data\n",
    "recon_dir = f\"{saving_paths.recon_output_dir}/{first_ens}/{first_mem}\"    \n",
    "recon_path = f\"{recon_dir}/recon_pCO2_{first_ens}_{first_mem}_mon_1x1_{init_date}_{fin_date}.zarr\"\n",
    "full = xr.open_zarr(recon_path)[\"pCO2_recon_full\"]\n",
    "\n",
    "# Choose a specific month to visualize\n",
    "chosen_time = '2021-01'\n",
    "raw_data = member_data[\"spco2\"].sel(time=chosen_time).squeeze()\n",
    "recon_data = full.sel(time=chosen_time)[0, ...]\n",
    "\n",
    "# Shift longitudes from [0, 360] to [-180, 180] for global plotting\n",
    "raw_data = raw_data.roll(xlon=len(raw_data.xlon) // 2, roll_coords=True)\n",
    "recon_data = recon_data.roll(xlon=len(recon_data.xlon) // 2, roll_coords=True)\n",
    "\n",
    "# Load SOCAT mask and align longitude\n",
    "socat_mask_data = xr.open_zarr(saving_paths.socat_path).sel(time=slice(str(dates[0]),str(dates[-1])))\n",
    "mask = socat_mask_data.sel(time=chosen_time)[\"socat_mask\"].squeeze()\n",
    "mask = mask.roll(xlon=len(mask.xlon) // 2, roll_coords=True)\n",
    "\n",
    "# Mask original data where SOCAT mask == 0\n",
    "masked_raw = np.ma.masked_array(raw_data, mask=(mask == 0))\n",
    "\n",
    "# Start plotting side-by-side\n",
    "with plt.style.context(plot_style):\n",
    "#    fig = plt.figure(figsize=(10, 4), dpi=200)\n",
    "    fig = plt.figure(figsize=(8, 3), dpi=200)\n",
    "    worldmap = SpatialMap2(\n",
    "        fig=fig, region='world',\n",
    "        cbar_mode='single',  # Use one shared colorbar\n",
    "        colorbar=True,\n",
    "        cbar_location='bottom',\n",
    "        nrows_ncols=[1, 2]\n",
    "    )\n",
    "\n",
    "    # Plot original (masked) and reconstructed data\n",
    "    sub0 = worldmap.add_plot(\n",
    "        lon=raw_data['xlon'], lat=raw_data['ylat'], data=masked_raw,\n",
    "        vrange=vrange, cmap=cmap, ax=0\n",
    "    )\n",
    "    sub1 = worldmap.add_plot(\n",
    "        lon=recon_data['xlon'], lat=recon_data['ylat'], data=recon_data,\n",
    "        vrange=vrange, cmap=cmap, ax=1\n",
    "    )\n",
    "\n",
    "    worldmap.set_title(\"Original pCO₂ (2021-01)\", ax=0, fontsize=13)\n",
    "    worldmap.set_title(\"Reconstructed pCO₂ (2021-01)\", ax=1, fontsize=13)\n",
    "\n",
    "    colorbar = worldmap.add_colorbar(sub0, ax=0)\n",
    "    worldmap.set_cbar_xlabel(colorbar, cbar_title, fontsize=12)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8eede-3be3-4498-b6b3-19f5a2c9c65b",
   "metadata": {},
   "source": [
    "The figure compares the original sparse pCO₂ selected from the first ESM member, consistent with real-world sampling, and the corresponding machine-learning-based reconstruction for January 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7e41f-cb49-40a6-aec5-a8178353fd27",
   "metadata": {},
   "source": [
    "# 5. Evaluation of the reconstruction against the original model output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3238f61a-ef41-4df9-9ef9-ece5b0f7bcab",
   "metadata": {},
   "source": [
    "## 5.1 Create a combined dataset with reconstruction and original "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c5029-af92-4678-8ac6-1f716939e4ec",
   "metadata": {},
   "source": [
    "We concatenate the outputs and ground truth from all members and ESMs into a single dataset, and then use this combined dataset to calculate bias, RMSE, and correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb6e9d-fedc-4c5d-a87a-121972d9f233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for ensemble, members in selected_mems_dict.items():\n",
    "    mems_dict = {ensemble: members}  \n",
    "    ds = concat_datasets(mems_dict, recon_output_dir = saving_paths.recon_output_dir, init_date = init_date, fin_date=fin_date)\n",
    "    datasets.append(ds)\n",
    "concated_dataset = xr.concat(datasets, dim=\"ens\")\n",
    "evaluator = XarrayEvaluator(concated_dataset)\n",
    "\n",
    "ds_eval = evaluator.compute_all_metrics()\n",
    "print(ds_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ec9749-619d-425b-97d8-15dbbd7fb205",
   "metadata": {},
   "source": [
    "## 5.2 Descriptive Statistics\n",
    "\n",
    "We can use ds_eval to easily compute descriptive statistics. In this example, we take the average across all time steps and ESMs:\n",
    "\n",
    "In this example, we select the Northern Hemisphere (ylat from 0 to 90), flatten the spatial dimensions, drop missing values, and generate a summary using describe(). This gives us a statistical overview (mean, std, min, max, etc.) of the bias in the Northern Hemisphere.\n",
    "\n",
    "You can change the selection for other regions and timeframes and ensemble members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e35d0b-58c2-4694-aabb-9c6b8301bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eval_mean = (ds_eval['bias']*1).mean('ens').mean('time')\n",
    "ds_eval_mean.sel(ylat=slice(0,90)).stack(z=['ylat','xlon']).dropna('z').to_dataframe().describe()['bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a172ba-f592-4e62-97c3-bbef03d536a2",
   "metadata": {},
   "source": [
    "## 5.3 Bias Visualizations\n",
    "Based on this, we could visualize bias between reconstruction and model truth, averaged over the 100 ensemble members, each with a \n",
    "monthly resolution over the period init_date through fin_date. Red and blue shading indicates regions where the reconstruction is biased high or low, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c31f484-007d-4f11-8c14-8f24c1e419dc",
   "metadata": {},
   "source": [
    "### 5.3.1 How well does the reconstruction capture the mean pCO2 field? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2182c4d-be60-46cc-a132-c68b79bcc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_style = \"seaborn-v0_8-talk\"\n",
    "\n",
    "with plt.style.context(plot_style):\n",
    "    fig = plt.figure(figsize=(8.5, 11)) # fig = plt.figure(dpi=300)\n",
    "    worldmap = SpatialMap2(fig=fig, region='world', \n",
    "                           cbar_mode='single',  \n",
    "                           colorbar=True,  \n",
    "                           cbar_location='bottom',\n",
    "                           nrows_ncols=[1,1])\n",
    "    vrange = [-10, 10, 5] \n",
    "    cmap = cm.cm.balance\n",
    "    \n",
    "    data = (ds_eval['bias'] * 1).mean('ens').mean('member').mean('time')\n",
    "    data = data.roll(xlon=len(data.xlon) // 2, roll_coords=True)\n",
    "    \n",
    "    data = xr_add_cyclic_point(data, cyclic_coord='xlon') \n",
    "    sub = worldmap.add_plot(lon=data['xlon'], lat=data['ylat'], data=data, \n",
    "                            vrange=vrange[0:2], cmap=cm.cm.balance, ax=0, linewidth_coast=0.5)\n",
    "    \n",
    "    col = worldmap.add_colorbar(sub, ax=0, extend='both')\n",
    "    worldmap.set_cbar_xlabel(col, 'Mean bias [uatm]', fontsize=14)\n",
    "    worldmap.set_ticks(col, vrange[0], vrange[1], vrange[2])\n",
    "    col.ax.tick_params(labelsize=12)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77200d8f-27a6-404c-bbe6-7b1bc6d0df0d",
   "metadata": {},
   "source": [
    "### 5.3.2 Does ESM impact the estimate of the bias? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f3747-69fe-4733-9729-a430d7790da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_style = \"seaborn-v0_8-talk\"\n",
    "ensemble_means = ds_eval['bias'].mean(dim=['member', 'time'])\n",
    "\n",
    "ensemble_names = list(ds_eval['ens'].values) \n",
    "\n",
    "vrange = [-10,10, 5]\n",
    "cmap = cm.cm.balance\n",
    "\n",
    "num_ensemble = len(ensemble_names)  \n",
    "num_cols = 3  \n",
    "num_rows = (num_ensemble + num_cols - 1) // num_cols \n",
    "with plt.style.context(plot_style):\n",
    "    fig = plt.figure(dpi=300)\n",
    "    worldmap = SpatialMap2(fig=fig, region='world', \n",
    "                           cbar_mode='single',  \n",
    "                           colorbar=True,  \n",
    "                           cbar_location='bottom',\n",
    "                           nrows_ncols=[num_rows, num_cols]) \n",
    "    for i in range(num_ensemble):\n",
    "        data = ensemble_means.isel(ens=i)\n",
    "        data = data.roll(xlon=len(data.xlon) // 2, roll_coords=True)  \n",
    "        data = xr_add_cyclic_point(data, cyclic_coord='xlon') \n",
    "        sub = worldmap.add_plot(lon=data['xlon'], lat=data['ylat'], data=data, \n",
    "                                vrange=vrange[0:2], cmap=cmap, ax=i, linewidth_coast=0.5)\n",
    "        worldmap.set_title(title=ensemble_names[i], ax=i, fontsize=14)\n",
    "\n",
    "    col = worldmap.add_colorbar(sub, ax=0, extend='both')\n",
    "    worldmap.set_cbar_xlabel(col, 'Mean bias [uatm]', fontsize=14)\n",
    "\n",
    "    worldmap.set_ticks(col, tmin=vrange[0], tmax=vrange[1], dt=vrange[2])\n",
    "\n",
    "    col.ax.tick_params(labelsize=12)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35974847-357a-4aab-8a5e-1bb271b005ce",
   "metadata": {},
   "source": [
    "##  5.2 Reconstructed variability on seasonal, sub-decadal, and decadal timescales, compared to original model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf3633-dde0-45e0-9e83-67b176c26543",
   "metadata": {},
   "source": [
    "Before computing spatial correlation metrics, we decompose both the reconstructed and reference pCO₂ fields into their long-term trend, seasonal cycle, and residual components using STL-like decomposition. We then evaluate their agreement by calculating gridwise correlation and standard deviation for each component across all ensemble members and ESMs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a57a1-e28a-4fd7-bdb8-53150eeca665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The calculation of these statistics takes about 1 min/member\n",
    "ds_eval_corr = eval_spatial(selected_mems_dict, saving_paths.recon_output_dir, init_date, fin_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a175f-5738-46fa-b45d-0740bb76f52c",
   "metadata": {},
   "source": [
    "Phasing of reconstruction variability on seasonal, sub-decadal, and decadal, compared to original model. Correlation between \n",
    "reconstruction and original model on (a) seasonal, (b) sub-decadal, and (c) decadal time scales. \n",
    "\n",
    "Here, the average correlations across all ensemble members are shown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838db47-8381-4557-85e5-78704fc16cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_style = \"seaborn-v0_8-talk\"\n",
    "\n",
    "with plt.style.context(plot_style):\n",
    "    # Setup Figure\n",
    "    fig = plt.figure(figsize=(8.5, 11)) # fig = plt.figure(dpi=300)\n",
    "    worldmap = SpatialMap2(fig=fig, region='world',\n",
    "                   cbar_mode='edge',\n",
    "                   axes_pad=0.15,\n",
    "                   colorbar=True,\n",
    "                   cbar_location='bottom',\n",
    "                   nrows_ncols=[3,1])\n",
    "    \n",
    "    # Colorbar ranges\n",
    "    vrange_col1 = [0, 1, 0.2]\n",
    "    cmap_col1 = cm.cm.oxy\n",
    "    \n",
    "    ##-----------------------------------------------------\n",
    "    ## Ensemble mean\n",
    "    ##-----------------------------------------------------\n",
    "    # Correlation - Annual-variation\n",
    "    data = ds_eval_corr['corr_seasonal'].mean('ens').mean('member')\n",
    "    data = data.roll(xlon=len(data.xlon) // 2, roll_coords=True)\n",
    "\n",
    "    data = xr_add_cyclic_point(data, cyclic_coord='xlon')\n",
    "    sub0 = worldmap.add_plot(lon=data['xlon'], lat=data['ylat'], data=data, \n",
    "                            vrange=vrange_col1[0:2], cmap=cmap_col1, ax=0)\n",
    "    \n",
    "    \n",
    "    # Correlation - sub-decadal\n",
    "    data = ds_eval_corr['corr_residual'].mean('ens').mean('member')\n",
    "    data = data.roll(xlon=len(data.xlon) // 2, roll_coords=True)\n",
    "    data = xr_add_cyclic_point(data, cyclic_coord='xlon')\n",
    "    sub2 = worldmap.add_plot(lon=data['xlon'], lat=data['ylat'], data=data, \n",
    "                            vrange=vrange_col1[0:2], cmap=cmap_col1, ax=1)\n",
    "    \n",
    "    # Correlation - decadal\n",
    "    data = ds_eval_corr['corr_dec'].mean('ens').mean('member')\n",
    "    data = data.roll(xlon=len(data.xlon) // 2, roll_coords=True)\n",
    "    data = xr_add_cyclic_point(data, cyclic_coord='xlon')\n",
    "    sub4 = worldmap.add_plot(lon=data['xlon'], lat=data['ylat'], data=data, \n",
    "                            vrange=vrange_col1[0:2], cmap=cmap_col1, ax=2)\n",
    "    \n",
    "    # add colorbar\n",
    "    col1 = worldmap.add_colorbar(sub0, ax=0, extend='min')\n",
    "    worldmap.set_cbar_xlabel(col1, f'Mean correlation')\n",
    "    worldmap.set_ticks(col1, vrange_col1[0], vrange_col1[1], vrange_col1[2])\n",
    "\n",
    "    worldmap.grid[0].text(-0.2, 0.5, \"Seasonal\", transform=worldmap.grid[0].transAxes,\n",
    "                           fontsize=14, fontweight='bold', va='center', ha='right', rotation=90)\n",
    "    \n",
    "    worldmap.grid[1].text(-0.2, 0.5, \"Sub-seasonal\", transform=worldmap.grid[1].transAxes,\n",
    "                           fontsize=14, fontweight='bold', va='center', ha='right', rotation=90)\n",
    "    \n",
    "    worldmap.grid[2].text(-0.2, 0.5, \"Decadal\", transform=worldmap.grid[2].transAxes,\n",
    "                           fontsize=14, fontweight='bold', va='center', ha='right', rotation=90)\n",
    "\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71149bef-ea1c-4dec-a162-e2d824747b55",
   "metadata": {},
   "source": [
    "The reconstructed pCO₂ has highest fidelity on seasonal timescales, but is less accurate for sub-seasonal and decadal timescale variability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424c84e-ddb7-479b-af4b-2c514cbd9e11",
   "metadata": {},
   "source": [
    "### **Final Check for Redundant Files**  \n",
    "\n",
    "#### **For Both Owners and Reviewers:**  \n",
    "After execution is complete, review the project directory for any redundant files. Ensure that only necessary and relevant files are retained.  \n",
    "\n",
    "#### **For Reviewers:**  \n",
    "Once you have finished reviewing a project, you may delete files related to that project to free up storage space. However, be careful not to remove any data you still need.\n",
    "\n",
    "As an **owner**, your reconstruction data is stored under:  \n",
    "\n",
    "```\n",
    "gs://leap-persistent/{owner_username}/{owner_username}/pco2_residual/nmse/post02_xgb/reconstructions/\n",
    "```\n",
    "\n",
    "If you are **reviewing someone else’s project**, their data and experiment results will be stored under your username in the following path:  \n",
    "\n",
    "```\n",
    "gs://leap-persistent/{your_username}/{owner_username}/pco2_residual/nmse/post02_xgb/reconstructions/\n",
    "```\n",
    "\n",
    "After completing the review, you can delete the files under `{owner_username}` in your directory to free up storage space. This ensures that only necessary data is retained while removing redundant files from past reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb802b8b-779a-4a0e-9ad2-a47c20039dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if runthiscell == -1:   # Only reviewers should delete data under this path. Everyone should clear redundant data, but be cautious not to delete necessary files.\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(\"leap-persistent\")\n",
    "    \n",
    "    prefix = f\"{your_username}/{owner_username}/pco2_residual/nmse/post02_xgb/reconstructions/\"\n",
    "    \n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    \n",
    "    files_deleted = 0\n",
    "    for blob in blobs:\n",
    "        try:\n",
    "            blob.delete()\n",
    "            print(f\"Deleted: {blob.name}\")\n",
    "            files_deleted += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete: {blob.name}\")\n",
    "            print(e)\n",
    "    \n",
    "    if files_deleted > 0:\n",
    "        print(f\"Successfully deleted {files_deleted} files under {reviewing_owner}'s directory.\")\n",
    "    else:\n",
    "        print(f\"No files found for {reviewing_owner}. Nothing was deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c1cf6-33d3-4e13-9bda-0b01d315d59d",
   "metadata": {},
   "source": [
    "# 6. Additional Information and Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f39a5-2aaf-45f4-ac09-b29471074a7c",
   "metadata": {},
   "source": [
    "This Python-based JupyterNotebook and associated utility files have been developed for Project 3 in the course EESC4243/STAT4243/5243 \"Climate Prediction Challenges with Machine Learning\", Professor Galen McKinley in DEES and Professor Tian Zheng in Statistics, Spring 2025 at Columbia University. The course is also a contribution from the NSF-supported LEAP STC and is intended to run on the LEAP-Pangeo cloud computing and data system. The Github repository for this course is at https://github.com/leap-stc/LEAPCourse-Climate-Pred-Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e14003-4686-4a17-aafb-bfdca4fcf680",
   "metadata": {},
   "source": [
    "Code developed by Course TA Xinyi Ke and Professor Galen McKinley, following from prior work from Dr. Thea Heimdal and Abby Shaum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13a819-43df-4d82-b963-e78910374e66",
   "metadata": {},
   "source": [
    "\n",
    "Additional references in which these methods are employed\\\n",
    "**Heimdal et al. (2024)** *\"Assessing improvements in global ocean pCO₂ machine learning reconstructions with Southern Ocean autonomous sampling.\"* **Biogeosciences** 21: 2159–2176.  \n",
    "([DOI: 10.5194/bg-21-2159-2024](https://doi.org/10.5194/bg-21-2159-2024))\\\n",
    "**Heimdal, T. H., & McKinley, G. A. (2024)** *\"The importance of adding unbiased Argo observations to the ocean carbon observing system.\"* **Scientific Reports**, 14(1), 19763. ([DOI: 10.1038/s41598-024-70617-x](https://doi.org/10.1038/s41598-024-70617-x) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
