{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is This??\n",
    "\n",
    "Hacked-up version of the decision tree model training thing so that you can train one locally.\n",
    "\n",
    "You will need to download the data file from gdrive - sam will provide a link.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import gcsfs\n",
    "import datetime\n",
    "import xarray as xr\n",
    "import random\n",
    "import xgboost as xgb     \n",
    "from xgboost import XGBRegressor\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_splits(X, y, train_val_idx, train_idx, val_idx, test_idx):\n",
    "    \n",
    "    \"\"\"\n",
    "    Uses splitting indeces found in 'train_val_test_split' to apply splits. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pandas.Dataframe\n",
    "        Dataframe of feature data\n",
    "    \n",
    "    y : pandas.Dataframe\n",
    "        Dataframe of target data\n",
    "    \n",
    "    train_val_idx : list\n",
    "        Indeces for combined training and validation dataset\n",
    "    \n",
    "    train_idx : list\n",
    "        Indeces for training dataset\n",
    "    \n",
    "    val_idx : list\n",
    "        Indeces for validation dataset\n",
    "    \n",
    "    test_idx : list\n",
    "        Indeces for testing dataset\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    X_train_val : pandas.Dataframe\n",
    "        Combined train and validation set\n",
    "    X_train : pandas.Dataframe\n",
    "        Training set\n",
    "    X_val : pandas.Dataframe\n",
    "        Validation set\n",
    "    X_test : pandas.Dataframe\n",
    "        Test set\n",
    "    y_train_val : pandas.Dataframe\n",
    "        Target values for train and validation set\n",
    "    y_train : pandas.Dataframe\n",
    "        Target values for training set\n",
    "    y_val : pandas.Dataframe\n",
    "        Target values for validation set\n",
    "    y_test : pandas.Dataframe\n",
    "        Target values for test set\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train_val = X[train_val_idx,:]\n",
    "    X_train = X[train_idx,:]\n",
    "    X_val = X[val_idx,:]\n",
    "    X_test = X[test_idx,:]\n",
    "\n",
    "    y_train_val = y[train_val_idx]\n",
    "    y_train = y[train_idx]\n",
    "    y_val = y[val_idx]\n",
    "    y_test = y[test_idx]\n",
    "\n",
    "    return X_train_val, X_train, X_val, X_test, y_train_val, y_train, y_val, y_test\n",
    "\n",
    "def train_val_test_split(N, test_prop, val_prop):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get indeces for splitting training and test sets for ML.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : Number of months\n",
    "    \n",
    "    test_prop : float\n",
    "        Proportion of data to use for testing, percentage\n",
    "    \n",
    "    val_prop : float\n",
    "        Proportion of data to use for validation, percentage\n",
    "    \n",
    "    random_seeds : list\n",
    "        Random numbers/seeds for partitioning randomly\n",
    "    \n",
    "    ens_count : int\n",
    "        Random seed stop point for ensemble member\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    intermediate_idx : list\n",
    "        Indeces for combined training and validation dataset\n",
    "        \n",
    "    train_idx : list\n",
    "        Indeces for training dataset\n",
    "        \n",
    "    val_idx : list\n",
    "        Indeces for validation dataset\n",
    "        \n",
    "    test_idx : list\n",
    "        Indeces for testing dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # intermediate_idx, test_idx = train_test_split(range(N), test_size=test_prop, random_state=random_seeds[0,ens_count])\n",
    "    # train_idx, val_idx = train_test_split(intermediate_idx, test_size=val_prop/(1-test_prop), random_state=random_seeds[1,ens_count])\n",
    "    # return intermediate_idx, train_idx, val_idx, test_idx\n",
    "    if test_prop > 0:\n",
    "        # Perform test split\n",
    "        intermediate_idx, test_idx = train_test_split(\n",
    "            range(N), test_size=test_prop, random_state=RSEED\n",
    "        )\n",
    "    else:\n",
    "        # No test set, all data goes into train/val\n",
    "        intermediate_idx = np.arange(N)\n",
    "        test_idx = None  # No test set\n",
    "\n",
    "    # Split remaining data into train/val\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        intermediate_idx, \n",
    "        test_size=val_prop / (1 - test_prop) if test_prop > 0 else val_prop,\n",
    "        random_state=RSEED\n",
    "    )\n",
    "\n",
    "    return intermediate_idx, train_idx, val_idx, test_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range\n",
    "date_range_start = '2004-01-01T00:00:00.000000000'\n",
    "date_range_end = '2023-12-31T00:00:00.000000000'\n",
    "\n",
    "# create date vector, adds 14 days to start & end\n",
    "dates = pd.date_range(start=date_range_start, \n",
    "                      end=date_range_end,freq='MS')\n",
    "\n",
    "\n",
    "init_date = str(dates[0].year) + format(dates[0].month,'02d')\n",
    "fin_date = str(dates[-1].year) + format(dates[-1].month,'02d')\n",
    "\n",
    "### train-validate-test split proportions ###\n",
    "\n",
    "select_dates = []\n",
    "test_dates = []\n",
    "\n",
    "for i in range(0,len(dates)):\n",
    "    if i % 5 != 0:\n",
    "        select_dates.append(dates[i]) ### 80% train days set ###\n",
    "    if i % 5 == 0:\n",
    "        test_dates.append(dates[i]) ### 20% test days set ### \n",
    "\n",
    "### Then, the month numbers above are converted back to their respective datetime objects.\n",
    "\n",
    "year_mon = []\n",
    "\n",
    "for i in range(0,len(select_dates)):\n",
    "    \n",
    "    tmp = select_dates[i]\n",
    "    year_mon.append(f\"{tmp.year}-{tmp.month}\")\n",
    "    \n",
    "test_year_mon = []\n",
    "\n",
    "for i in range(0,len(test_dates)):    \n",
    "    tmp = test_dates[i]\n",
    "    test_year_mon.append(f\"{tmp.year}-{tmp.month}\")\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 500,  # Number of boosting rounds\n",
    "    'max_depth': 6,  # Maximum depth of each tree to control model complexity\n",
    "    'learning_rate': 0.05,  # Step size shrinkage to prevent overfitting\n",
    "    'subsample': 0.8,  # Fraction of samples used for training each tree\n",
    "    'colsample_bytree': 0.8,  # Fraction of features used per tree\n",
    "    'gamma': 0.1,  # Minimum loss reduction required for further partitioning\n",
    "    'min_child_weight': 5,  # Minimum sum of instance weight in a leaf node\n",
    "    'reg_alpha': 0.1,  # L1 regularization to reduce model complexity\n",
    "    'reg_lambda': 1.0,  # L2 regularization for preventing overfitting\n",
    "    'objective': 'reg:squarederror',  # Loss function for regression tasks\n",
    "    'n_jobs': 30,  # Number of parallel threads to use for training\n",
    "    'eval_metric': 'rmse',\n",
    "    'early_stopping_rounds': 50  # Stop training if performance doesn't improve for 50 rounds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sel = ['sst','sst_anom','sss','sss_anom','mld_clim_log','chl_log','chl_log_anom','xco2','A', 'B', 'C', 'T0', 'T1']\n",
    "val_prop = .2 # 20% of training data for validation\n",
    "test_prop = .0 # Since we apply this split to X_train, we set it to zero. We have X_test as testing dataset.\n",
    "\n",
    "# the target variable we reconstruct:\n",
    "target_sel = ['pco2_residual'] # this represents pCO2 - pCO2-T (calculated in notebook 00)\n",
    "\n",
    "file_path = 'data/MLinput_ACCESS-ESM1-5_r10i1p1f1_mon_1x1_200401_202312.pkl'\n",
    "random_seeds = [42]\n",
    "\n",
    "with open(file_path, 'rb') as filee:\n",
    "    df = pd.read_pickle(filee)\n",
    "    df['year'] = df.index.get_level_values('time').year\n",
    "    df['mon'] = df.index.get_level_values('time').month\n",
    "    df['year_month'] = df['year'].astype(str) + \"-\" + df['mon'].astype(str)\n",
    "    \n",
    "    recon_sel = (\n",
    "        ~df[features_sel+target_sel+['net_mask']].isna().any(axis=1)\n",
    "    ) & (\n",
    "        (df[target_sel] < 250) & (df[target_sel] > -250)\n",
    "    ).to_numpy().ravel()\n",
    "\n",
    "    sel = (recon_sel & (df['socat_mask'] == 1))\n",
    "    \n",
    "    train_sel = (sel & (pd.Series(df['year_month']).isin(year_mon))).to_numpy().ravel()\n",
    "    test_sel  = (sel & (pd.Series(df['year_month']).isin(test_year_mon))).to_numpy().ravel()\n",
    "    unseen_sel = (recon_sel & (df['socat_mask'] == 0))\n",
    "\n",
    "    X = df.loc[sel, features_sel].to_numpy()\n",
    "    y = df.loc[sel, target_sel].to_numpy().ravel()\n",
    "\n",
    "    Xtrain = df.loc[train_sel, features_sel].to_numpy()                \n",
    "    ytrain = df.loc[train_sel, target_sel].to_numpy().ravel()\n",
    "\n",
    "    X_test = df.loc[test_sel, features_sel].to_numpy()\n",
    "    y_test = df.loc[test_sel, target_sel].to_numpy().ravel()\n",
    "    N = Xtrain.shape[0]\n",
    "    \n",
    "    train_val_idx, train_idx, val_idx, test_idx = train_val_test_split(\n",
    "        N, test_prop, val_prop\n",
    "    )\n",
    "    X_train_val, X_train, X_val, X_test_tmp, y_train_val, y_train, y_val, y_test_tmp = \\\n",
    "        apply_splits(Xtrain, ytrain, train_val_idx, train_idx, val_idx, test_idx)   \n",
    "\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        random_state=42,\n",
    "        **params,\n",
    "    )\n",
    "    eval_set = [(X_val, y_val)] \n",
    "    model.fit(\n",
    "        X_train_val, y_train_val, \n",
    "        eval_set=eval_set, \n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
